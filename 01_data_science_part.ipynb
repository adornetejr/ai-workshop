{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler, Imputer, LabelBinarizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Set Dataset path and the file name to load.\n",
    "#\n",
    "DATASET_PATH = 'datasets/'\n",
    "FILE_NAME = 'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Load the dataset into Pandas (https://pandas.pydata.org/).\n",
    "#\n",
    "def load_dataset(dataset_path = DATASET_PATH, file_name = FILE_NAME):\n",
    "    return pd.read_csv(os.path.join(dataset_path, file_name))\n",
    "\n",
    "train_data = load_dataset()\n",
    "test_data = load_dataset(DATASET_PATH, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Show the first 5 lines of the dataset. It's useful to start know more about all the data.\n",
    "# Look at the data types, think about what you can split, others data to add. All here is useful?\n",
    "#\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get data type, length of dataset, if there are some data missing and more useful info.\n",
    "#\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Lets see the correlation between all these variables. What really matters when you need to \n",
    "# predict `Survived`? (second column) \n",
    "#\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_data.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Get some statistics about the current data. Mean, Std (http://www.purplemath.com/modules/meanmode.htm)\n",
    "#\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's see some info about the amount of the data. How many survivors? What about Age and Fare?\n",
    "#\n",
    "train_data.hist(figsize=(20,15))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Pclass and Age really matters for survivor people?\n",
    "#\n",
    "grid = sns.FacetGrid(train_data, col='Survived', row='Pclass', size=4, aspect=1.6)\n",
    "grid.map(plt.hist, 'Age', alpha=.5, bins=20)\n",
    "grid.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's think about what variables we can improve.\n",
    "#\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Some people don't have a cabin (workers) So, let's add another attribute to take care of this people.\n",
    "#\n",
    "train_data['HasCabin'] = train_data[\"Cabin\"].map(lambda x: 0 if type(x) == float else 1)\n",
    "test_data['HasCabin'] = test_data[\"Cabin\"].map(lambda x: 0 if type(x) == float else 1)\n",
    "\n",
    "\n",
    "#\n",
    "# Some registers is about the entire family. Let's add another attribute to know the family size.\n",
    "#\n",
    "train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch'] + 1\n",
    "test_data['FamilySize'] = test_data['SibSp'] + test_data['Parch'] + 1\n",
    "\n",
    "#\n",
    "# When people are alone, the family size is 1. Let's add this attribute to know after if this attribute correlates with survived.\n",
    "#\n",
    "train_data['IsAlone'] = train_data[\"FamilySize\"].map(lambda x: 1 if x == 1 else 0)\n",
    "test_data['IsAlone'] = test_data[\"FamilySize\"].map(lambda x: 1 if x == 1 else 0)\n",
    "\n",
    "#\n",
    "# Some people in Titanic are a child. We know women and children have the preference when got saved.\n",
    "# Let's add this attribute and see the correlation after.\n",
    "#\n",
    "train_data['IsChild'] = train_data[\"Age\"].map(lambda x: 1 if x < 16 else 0)\n",
    "test_data['IsChild'] = test_data[\"Age\"].map(lambda x: 1 if x < 16 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's see how are our data now.\n",
    "#\n",
    "train_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's correlate all variables. Yellow ones are highly correlated.\n",
    "#\n",
    "colormap = plt.cm.viridis\n",
    "plt.figure(figsize=(14,12))\n",
    "plt.title('Pearson Correlation of Features', y=1.05, size=15)\n",
    "sns.heatmap(train_data.corr(),linewidths=0.1,vmax=1.0, square=True, cmap=colormap, linecolor='white', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Ok, now we need to split our data to start doing some machine learning.\n",
    "# Our labels are the `survived` column, labels are the data that we need to predict based on another.\n",
    "#\n",
    "# PassengerId we don't need to know. We put in another variable to use after all.\n",
    "# Name is not useful to predict.\n",
    "# Ticket number don't tell us anything.\n",
    "# Cabin is expensive to know. Probably we can split the cabin into classes also: Class A, Class B. This is useful?\n",
    "#\n",
    "labels = train_data['Survived']\n",
    "passenger_id = test_data['PassengerId']\n",
    "\n",
    "\n",
    "train_data = train_data.drop(['Survived', 'PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)\n",
    "test_data = test_data.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# How are our training data?\n",
    "#\n",
    "train_data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# To predict info with machine learning, we need to transform our data to put on our logic (Classifier, NeuralNetworks, etc)\n",
    "# We need to remove from dataframe and get the raw value, Fill all empty values and Split our string into classes.\n",
    "# We also Scale our values to do all math without got so expensive. (http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html)\n",
    "#\n",
    "# The following 4 code blocks do this.\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes_names):\n",
    "        self.attributes_names = attributes_names\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return X[self.attributes_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FillNa(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, attributes_names, value):\n",
    "        self.attributes_names = attributes_names\n",
    "        self.value = value\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        data = X[self.attributes_names].fillna(self.value, inplace=True)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StringBinalizer(BaseEstimator, TransformerMixin):    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        label = LabelBinarizer()\n",
    "        return label.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numerical_attributes = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'HasCabin', 'FamilySize', 'IsAlone']\n",
    "\n",
    "numerical_pipeline = Pipeline([\n",
    "    ('selector', DataFrameSelector(numerical_attributes)),\n",
    "    ('imputer', Imputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "sex_pipeline = Pipeline([\n",
    "    ('selector_sex', DataFrameSelector('Sex')),\n",
    "    ('label_encoder', StringBinalizer())\n",
    "])\n",
    "\n",
    "embarked_pipeline = Pipeline([\n",
    "    ('fill_na', FillNa('Embarked', 'C')),\n",
    "    ('selector_embarked', DataFrameSelector('Embarked')),\n",
    "    ('label_binalizer', StringBinalizer())\n",
    "\n",
    "])\n",
    "\n",
    "full_pipeline = FeatureUnion(transformer_list=[\n",
    "    ('numerical_pipeline', numerical_pipeline),\n",
    "    ('sex_pipeline', sex_pipeline),\n",
    "    ('embarked_pipeline', embarked_pipeline)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Now, our data is raw, standardized, only with useful data to Classifier.\n",
    "#\n",
    "train_data_prepared = full_pipeline.fit_transform(train_data)\n",
    "test_data_prepared = full_pipeline.fit_transform(test_data)\n",
    "\n",
    "print(train_data_prepared[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Let's score and see how well is our data to predict new ones.\n",
    "# The score is between 0.0 and 1.0. 0 is dumb, 1.0 is clever\n",
    "#\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "model.fit(train_data_prepared, labels)\n",
    "model.score(train_data_prepared, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# We put all our predictions to csv to put in Kaggle platform. Send your csv and see how well is your model.\n",
    "#\n",
    "result = pd.DataFrame({ 'PassengerId': passenger_id, 'Survived': model.predict(test_data_prepared) })\n",
    "result.to_csv(\"01_data_science_part_result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
